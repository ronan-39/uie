{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d477ff3",
   "metadata": {},
   "source": [
    "This notebook outlines the code and provides a sample output.\n",
    "\n",
    "### Models\n",
    "Models are implemented in `./models`. The original UWCNN model is reimplemented in `./models/uwcnn.py`\n",
    "\n",
    "### Losses\n",
    "Losses are implemented in `./losses.py`. The main loss used during training is the sum of MSE and SSIM.\n",
    "\n",
    "### Depth prediction\n",
    "To predict depth, I use a pretrained depth prediction model based on DinoV2. In `./estimate_depth.py`, I use the PyTorch API to add depth estimation as a preprocessing step on UWDCNN inputs\n",
    "\n",
    "### Configuration\n",
    "Training settings and dataset locations are specified in `./config.toml`. The required fields are specified in `./config_example.toml`\n",
    "\n",
    "### Training\n",
    "Model construction and dataset preperation is handled in `./main.py`, and the actual training loop can be found in `./training.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f3c84e3",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms as transforms\n",
    "import tomllib\n",
    "from datasets import build_uied_dataset, build_depth_dataset\n",
    "from models import uwcnn, uwcnn_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a784dd",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "with open('./config.toml', 'rb') as f:\n",
    "    cfg = tomllib.load(f)\n",
    "\n",
    "model = uwcnn_depth.UWCNN_Depth()\n",
    "checkpoint = torch.load('./checkpoints/uwdcnn-base_nyu_type3_50_epoch.pth')\n",
    "model.load_state_dict(checkpoint)\n",
    "\n",
    "input_processor = transforms.Compose([\n",
    "    transforms.Normalize((0.5,), (0.5,)),\n",
    "])\n",
    "\n",
    "dataset_name = 'nyu_type3'\n",
    "dataset = build_depth_dataset(\n",
    "    images_dir = cfg['datasets'][dataset_name]['img'],\n",
    "    gt_dir = cfg['datasets'][dataset_name]['gt'],\n",
    "    depth_dir = cfg['datasets'][dataset_name]['depth']\n",
    ")\n",
    "\n",
    "img, label = dataset[1]\n",
    "input = input_processor(img.unsqueeze(0))\n",
    "\n",
    "with torch.no_grad():\n",
    "    prediction = model(input)\n",
    "\n",
    "fig, axs = plt.subplots(ncols=3, figsize=(15, 5))\n",
    "axs[0].imshow(img[:-1].permute(1,2,0))\n",
    "axs[0].set_title(\"input\")\n",
    "\n",
    "axs[1].imshow(label.permute(1,2,0))\n",
    "axs[1].set_title(\"ground truth\")\n",
    "\n",
    "axs[2].imshow(prediction[0].permute(1,2,0))\n",
    "axs[2].set_title(\"prediction\")\n",
    "\n",
    "for ax in axs:\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.set_aspect('equal')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
